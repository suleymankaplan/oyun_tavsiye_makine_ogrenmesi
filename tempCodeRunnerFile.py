import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import pickle

# --- 1. VERÄ°YÄ° YÃœKLEME ---
filename = "oyun_projesi_final_veri.csv"
try:
    df = pd.read_csv(filename)
    print(f"âœ… Veri baÅŸarÄ±yla yÃ¼klendi: {len(df)} satÄ±r")
except FileNotFoundError:
    try:
        df = pd.read_csv("oyun_tavsiye_makine_ogrenmesi/" + filename)
        print(f"âœ… Veri baÅŸarÄ±yla yÃ¼klendi (Alt klasÃ¶rden): {len(df)} satÄ±r")
    except FileNotFoundError:
        print("âŒ Hata: CSV dosyasÄ± bulunamadÄ±!")
        exit()


# --- 2. HEDEF BELÄ°RLEME (HIT PREDICTION) ---
# %25'lik dilimi (Top 25%) Hit kabul ediyoruz
threshold = df['num_reviews_total'].quantile(0.75)
df['is_hit'] = (df['num_reviews_total'] > threshold).astype(int)

print(f"\nğŸ¯ HEDEF: PopÃ¼lerlik Tahmini (EÅŸik DeÄŸeri: {threshold:.0f} inceleme)")
print(f"   Orijinal Hit SayÄ±sÄ±: {df['is_hit'].sum()}")
print(f"   Orijinal Niche SayÄ±sÄ±: {len(df) - df['is_hit'].sum()}")


# --- 3. VERÄ° DENGELEME (UNDERSAMPLING) ---
# Ä°steÄŸin Ã¼zerine: Hit sayÄ±sÄ± kadar Niche seÃ§ip durumu %50-%50 eÅŸitliyoruz.
df_hit = df[df['is_hit'] == 1]
df_niche = df[df['is_hit'] == 0]

# Niche olanlardan rastgele Hit sayÄ±sÄ± kadar al
df_niche_balanced = df_niche.sample(n=len(df_hit), random_state=42)

# Ä°kisini birleÅŸtir (ArtÄ±k elimizde dengeli bir veri seti var)
df_balanced = pd.concat([df_hit, df_niche_balanced])

print(f"\nâš–ï¸  VERÄ° DENGELENDÄ° (UNDERSAMPLING):")
print(f"   Yeni Veri Seti Boyutu: {len(df_balanced)}")
print(f"   Hit SayÄ±sÄ±: {df_balanced['is_hit'].sum()}")
print(f"   Niche SayÄ±sÄ±: {len(df_balanced) - df_balanced['is_hit'].sum()}")
print("   (Model artÄ±k %50 Hit - %50 Niche verisiyle eÄŸitilecek.)")


# --- 4. KORELASYON ANALÄ°ZÄ° ---
# Dengeli veri seti Ã¼zerinden korelasyona bakmak daha mantÄ±klÄ±dÄ±r.
print("\nğŸ“Š 1. KORELASYON MATRÄ°SÄ° OLUÅTURULUYOR...")

corr_cols = ['is_hit', 'final_price', 'metacritic_score', 
             'gen_action', 'gen_rpg', 'gen_indie', 'cat_multiplayer', 'is_recent']

# Sadece veri setinde mevcut olanlarÄ± al
existing_cols = [c for c in corr_cols if c in df_balanced.columns]
corr_matrix = df_balanced[existing_cols].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Oyun Ã–zellikleri ArasÄ±ndaki Korelasyon (Dengeli Veri)")
plt.tight_layout()
plt.savefig("korelasyon_matrisi.png")
print("   âœ… 'korelasyon_matrisi.png' kaydedildi.")


# --- 5. MODEL HAZIRLIÄI ---
# Modelin kopya Ã§ekmesini (Data Leakage) engellemek iÃ§in sÄ±zÄ±ntÄ± yapan sÃ¼tunlarÄ± atÄ±yoruz.
drop_cols = [
    'final_name', 'header_image', 'cluster_label', 'pca_x', 'pca_y', 
    'is_hit',             # Hedef
    'num_reviews_total',  # Hedefin kendisi
    'norm_reviews',       
    'num_reviews_recent', # âš ï¸ KOPYA: Son incelemeler
    'estimated_owners'    # âš ï¸ KOPYA: Sahip sayÄ±sÄ±
]
features = [col for col in df_balanced.columns if col not in drop_cols and df_balanced[col].dtype in [np.float64, np.int64]]

X = df_balanced[features]
y = df_balanced['is_hit']

# Veriyi BÃ¶lme (%70 EÄŸitim, %30 Test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


# --- 6. SINIFLANDIRMA VE CONFUSION MATRIX ---
print("\nğŸ¤– 2. SINIFLANDIRMA MODELÄ° (Decision Tree - Derinlik 8)...")

# Sabit derinlikte bir model eÄŸitelim
clf_fixed = DecisionTreeClassifier(max_depth=6, random_state=42)
clf_fixed.fit(X_train, y_train)
y_test_pred = clf_fixed.predict(X_test)

# Confusion Matrix Ã‡izimi
cm = confusion_matrix(y_test, y_test_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', 
            xticklabels=['Niche', 'Hit'], 
            yticklabels=['Niche', 'Hit'])
plt.title("Confusion Matrix (Dengeli 50/50)")
plt.xlabel("Tahmin Edilen")
plt.ylabel("GerÃ§ek Durum")
plt.tight_layout()
plt.savefig("confusion_matrix.png")
print("   âœ… 'confusion_matrix.png' kaydedildi.")

# Metrik Raporu
print("\n   ğŸ“„ SÄ±nÄ±flandÄ±rma Raporu:")
print(classification_report(y_test, y_test_pred))


# --- 7. OVERFITTING ANALÄ°ZÄ° ---
print("\nğŸ“ˆ 3. OVERFITTING GRAFÄ°ÄÄ° (Complexity Curve) Ã‡Ä°ZÄ°LÄ°YOR...")

depths = range(1, 21)
train_scores = []
test_scores = []

for depth in depths:
    clf = DecisionTreeClassifier(max_depth=depth, random_state=42)
    clf.fit(X_train, y_train)
    
    train_scores.append(accuracy_score(y_train, clf.predict(X_train)))
    test_scores.append(accuracy_score(y_test, clf.predict(X_test)))

# GrafiÄŸi Ã‡iz
plt.figure(figsize=(10, 6))
plt.plot(depths, train_scores, 'bo-', label='EÄŸitim BaÅŸarÄ±sÄ± (Train Accuracy)')
plt.plot(depths, test_scores, 'ro-', label='Test BaÅŸarÄ±sÄ± (Test Accuracy)')

# Optimal noktayÄ± bul ve iÅŸaretle
optimal_idx = np.argmax(test_scores)
optimal_depth = depths[optimal_idx]
max_test_score = test_scores[optimal_idx]

plt.axvline(x=optimal_depth, color='green', linestyle='--', label=f'En Ä°yi Derinlik ({optimal_depth})')
plt.title('Overfitting Analizi: AÄŸaÃ§ DerinliÄŸi vs BaÅŸarÄ± (Dengeli Veri)', fontsize=14)
plt.xlabel('AÄŸaÃ§ DerinliÄŸi (Max Depth)', fontsize=12)
plt.ylabel('DoÄŸruluk (Accuracy)', fontsize=12)
plt.legend()
plt.grid(True)
plt.xticks(depths)
# Dengeli olduÄŸu iÃ§in %50'den baÅŸlamasÄ± beklenir
plt.ylim(0.9, 1.0) 

plt.tight_layout()
plt.savefig("overfitting_analizi_grafigi.png")
print(f"   âœ… 'overfitting_analizi_grafigi.png' kaydedildi.")
print(f"   ğŸ‘‰ En iyi Test BaÅŸarÄ±sÄ±: %{max_test_score*100:.2f} (Derinlik {optimal_depth})")


# --- 8. MODELÄ° KAYDETME ---
print("\nğŸ’¾ 4. MODEL KAYDEDÄ°LÄ°YOR...")

# DÄ°KKAT: DÃ¶ngÃ¼deki son model (depth=20) yerine, 
# Overfitting yapmayan ideal derinlikteki (Ã¶rn: 8) modeli tÃ¼m dengeli veriyle eÄŸitip kaydediyoruz.
final_clf = DecisionTreeClassifier(max_depth=6, random_state=42)
final_clf.fit(X, y)

with open("hit_model.pkl", "wb") as f:
    pickle.dump(final_clf, f)

print(f"âœ… 'hit_model.pkl' baÅŸarÄ±yla kaydedildi.")