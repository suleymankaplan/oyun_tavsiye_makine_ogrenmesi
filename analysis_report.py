import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import pickle

# --- 1. VERÄ°YÄ° YÃœKLEME ---
filename = "oyun_projesi_final_veri.csv"
try:
    df = pd.read_csv(filename)
    print(f"âœ… Veri baÅŸarÄ±yla yÃ¼klendi: {len(df)} satÄ±r")
except FileNotFoundError:
    try:
        df = pd.read_csv("oyun_tavsiye_makine_ogrenmesi/" + filename)
        print(f"âœ… Veri baÅŸarÄ±yla yÃ¼klendi (Alt klasÃ¶rden): {len(df)} satÄ±r")
    except FileNotFoundError:
        print("âŒ Hata: CSV dosyasÄ± bulunamadÄ±!")
        exit()

# --- 2. HEDEF BELÄ°RLEME (HIT PREDICTION) ---
# Medyan deÄŸerin Ã¼zerindekilere "1" (Hit), altÄ±na "0" (Niche) diyelim.
threshold = df['num_reviews_total'].median()
df['is_hit'] = (df['num_reviews_total'] > threshold).astype(int)

print(f"\nðŸŽ¯ HEDEF: PopÃ¼lerlik Tahmini (EÅŸik DeÄŸeri: {threshold:.0f} inceleme)")
print(f"   Hit Olanlar (1): {df['is_hit'].sum()}")
print(f"   Niche Olanlar (0): {len(df) - df['is_hit'].sum()}")

# Model Girdileri (Features)
drop_cols = ['final_name', 'header_image', 'cluster_label', 'pca_x', 'pca_y', 
             'num_reviews_total', 'norm_reviews', 'is_hit']
features = [col for col in df.columns if col not in drop_cols and df[col].dtype in [np.float64, np.int64]]

X = df[features]
y = df['is_hit']

# Veriyi BÃ¶lme (%70 EÄŸitim, %30 Test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


# --- 3. KORELASYON ANALÄ°ZÄ° (GÃ–REV 1) ---
print("\nðŸ“Š 1. KORELASYON MATRÄ°SÄ° OLUÅžTURULUYOR...")

# Analiz edilecek sayÄ±sal sÃ¼tunlar (Fiyat, Puan, TÃ¼r Ä°liÅŸkisi)
corr_cols = ['final_price', 'metacritic_score', 
             'gen_action', 'gen_rpg', 'gen_indie', 'cat_multiplayer', 'is_recent','is_hit']

# Sadece veri setinde mevcut olanlarÄ± al
existing_cols = [c for c in corr_cols if c in df.columns]
corr_matrix = df[existing_cols].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Oyun Ã–zellikleri ArasÄ±ndaki Korelasyon")
plt.tight_layout()
plt.savefig("korelasyon_matrisi.png")
print("   âœ… 'korelasyon_matrisi.png' kaydedildi.")




# --- 4. SINIFLANDIRMA VE CONFUSION MATRIX (GÃ–REV 2 & 3) ---
print("\nðŸ¤– 2. SINIFLANDIRMA MODELÄ° (Decision Tree - Derinlik 8)...")

# Tek bir model eÄŸitiyoruz (Confusion Matrix iÃ§in)
clf_fixed = DecisionTreeClassifier(max_depth=8, random_state=42)
clf_fixed.fit(X_train, y_train)
y_test_pred = clf_fixed.predict(X_test)

# Confusion Matrix Ã‡izimi
cm = confusion_matrix(y_test, y_test_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', 
            xticklabels=['Niche', 'Hit'], 
            yticklabels=['Niche', 'Hit'])
plt.title("Confusion Matrix (PopÃ¼lerlik Tahmini)")
plt.xlabel("Tahmin Edilen")
plt.ylabel("GerÃ§ek Durum")
plt.tight_layout()
plt.savefig("confusion_matrix.png")
print("   âœ… 'confusion_matrix.png' kaydedildi.")

# Metrik Raporu
print("\n   ðŸ“„ SÄ±nÄ±flandÄ±rma Raporu:")
print(classification_report(y_test, y_test_pred))


# --- 5. DETAYLI OVERFITTING ANALÄ°ZÄ° VE GRAFÄ°ÄžÄ° (GÃ–REV 4) ---
print("\nðŸ“ˆ 3. OVERFITTING GRAFÄ°ÄžÄ° (Complexity Curve) Ã‡Ä°ZÄ°LÄ°YOR...")

depths = range(1, 21)
train_scores = []
test_scores = []

# DÃ¶ngÃ¼ ile her derinliÄŸi test et
for depth in depths:
    clf = DecisionTreeClassifier(max_depth=depth, random_state=42)
    clf.fit(X_train, y_train)
    
    train_scores.append(accuracy_score(y_train, clf.predict(X_train)))
    test_scores.append(accuracy_score(y_test, clf.predict(X_test)))

# GrafiÄŸi Ã‡iz
plt.figure(figsize=(10, 6))
plt.plot(depths, train_scores, 'bo-', label='EÄŸitim BaÅŸarÄ±sÄ± (Train Accuracy)')
plt.plot(depths, test_scores, 'ro-', label='Test BaÅŸarÄ±sÄ± (Test Accuracy)')

# Optimal noktayÄ± bul ve iÅŸaretle
optimal_idx = np.argmax(test_scores)
optimal_depth = depths[optimal_idx]
max_test_score = test_scores[optimal_idx]

plt.axvline(x=optimal_depth, color='green', linestyle='--', label=f'En Ä°yi Derinlik ({optimal_depth})')
plt.title('Overfitting Analizi: AÄŸaÃ§ DerinliÄŸi vs BaÅŸarÄ±', fontsize=14)
plt.xlabel('AÄŸaÃ§ DerinliÄŸi (Max Depth)', fontsize=12)
plt.ylabel('DoÄŸruluk (Accuracy)', fontsize=12)
plt.legend()
plt.grid(True)
plt.xticks(depths)

plt.tight_layout()
plt.savefig("overfitting_analizi_grafigi.png")
print(f"   âœ… 'overfitting_analizi_grafigi.png' kaydedildi.")
print(f"   ðŸ‘‰ En iyi Test BaÅŸarÄ±sÄ±: %{max_test_score*100:.2f} (Derinlik {optimal_depth})")

with open("hit_model.pkl", "wb") as f:
    pickle.dump(clf, f)

print("\nâœ… TÃœM Ä°ÅžLEMLER TAMAMLANDI. Rapor iÃ§in 3 adet PNG dosyasÄ± hazÄ±r.")